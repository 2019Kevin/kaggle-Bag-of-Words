{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "问题描述： <strong>二分类问题</strong><br>\n",
    "问题描述：<strong>根据测试集电影评论的内容预测评论者的情感分析: 1表示正面评价, 0表示负面评价。</strong><br>\n",
    "评价指标：<strong>AUC</strong><br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 数据集的每条记录以\"\\t\"为分隔符, quotion=3表示读取数据时忽略双引号\n",
    "data_train = pd.read_csv(\"labeledTrainData.tsv\",delimiter='\\t', quoting=3)\n",
    "data_test = pd.read_csv(\"testData.tsv\", delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的形状 (25000, 3)\n",
      "测试集的形状 (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集的形状\", data_train.shape)\n",
    "print(\"测试集的形状\", data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "看看训练集的一条影评的具体内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"A friend of mine bought this film for £1, and even then it was grossly overpriced. Despite featuring big names such as Adam Sandler, Billy Bob Thornton and the incredibly talented Burt Young, this film was about as funny as taking a chisel and hammering it straight through your earhole. It uses tired, bottom of the barrel comedic techniques - consistently breaking the fourth wall as Sandler talks to the audience, and seemingly pointless montages of \\'hot girls\\'.<br /><br />Adam Sandler plays a waiter on a cruise ship who wants to make it as a successful comedian in order to become successful with women. When the ship\\'s resident comedian - the shamelessly named \\'Dickie\\' due to his unfathomable success with the opposite gender - is presumed lost at sea, Sandler\\'s character Shecker gets his big break. Dickie is not dead, he\\'s rather locked in the bathroom, presumably sea sick.<br /><br />Perhaps from his mouth he just vomited the worst film of all time.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"review\"][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗与文本处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以一条影评为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>1,&emsp;对一条影评论初始化为BeautifulSoup对象</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data_train[\"review\"][8], 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>2,&emsp;利用get_text()方法获取这条影评所有标签的文本内容。这将除去文档中的所有标签符号</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"A friend of mine bought this film for £1, and even then it was grossly overpriced. Despite featuring big names such as Adam Sandler, Billy Bob Thornton and the incredibly talented Burt Young, this film was about as funny as taking a chisel and hammering it straight through your earhole. It uses tired, bottom of the barrel comedic techniques - consistently breaking the fourth wall as Sandler talks to the audience, and seemingly pointless montages of \\'hot girls\\'.Adam Sandler plays a waiter on a cruise ship who wants to make it as a successful comedian in order to become successful with women. When the ship\\'s resident comedian - the shamelessly named \\'Dickie\\' due to his unfathomable success with the opposite gender - is presumed lost at sea, Sandler\\'s character Shecker gets his big break. Dickie is not dead, he\\'s rather locked in the bathroom, presumably sea sick.Perhaps from his mouth he just vomited the worst film of all time.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = soup.get_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>3,&emsp;利用正则表达式将这条文本内容中不是字母的所有其他字符全部替换成空格</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A friend of mine bought this film for     and even then it was grossly overpriced  Despite featuring big names such as Adam Sandler  Billy Bob Thornton and the incredibly talented Burt Young  this film was about as funny as taking a chisel and hammering it straight through your earhole  It uses tired  bottom of the barrel comedic techniques   consistently breaking the fourth wall as Sandler talks to the audience  and seemingly pointless montages of  hot girls  Adam Sandler plays a waiter on a cruise ship who wants to make it as a successful comedian in order to become successful with women  When the ship s resident comedian   the shamelessly named  Dickie  due to his unfathomable success with the opposite gender   is presumed lost at sea  Sandler s character Shecker gets his big break  Dickie is not dead  he s rather locked in the bathroom  presumably sea sick Perhaps from his mouth he just vomited the worst film of all time  '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>4,&emsp;将这条文本中的所有字符全部转换为小写,</strong><br>\n",
    "<strong>&emsp;&emsp;再利用split()方法拆分成单词列表, 同时消除了所有空白字符</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'friend', 'of', 'mine', 'bought', 'this', 'film', 'for', 'and', 'even', 'then', 'it', 'was', 'grossly', 'overpriced', 'despite', 'featuring', 'big', 'names', 'such', 'as', 'adam', 'sandler', 'billy', 'bob', 'thornton', 'and', 'the', 'incredibly', 'talented', 'burt', 'young', 'this', 'film', 'was', 'about', 'as', 'funny', 'as', 'taking', 'a', 'chisel', 'and', 'hammering', 'it', 'straight', 'through', 'your', 'earhole', 'it', 'uses', 'tired', 'bottom', 'of', 'the', 'barrel', 'comedic', 'techniques', 'consistently', 'breaking', 'the', 'fourth', 'wall', 'as', 'sandler', 'talks', 'to', 'the', 'audience', 'and', 'seemingly', 'pointless', 'montages', 'of', 'hot', 'girls', 'adam', 'sandler', 'plays', 'a', 'waiter', 'on', 'a', 'cruise', 'ship', 'who', 'wants', 'to', 'make', 'it', 'as', 'a', 'successful', 'comedian', 'in', 'order', 'to', 'become', 'successful', 'with', 'women', 'when', 'the', 'ship', 's', 'resident', 'comedian', 'the', 'shamelessly', 'named', 'dickie', 'due', 'to', 'his', 'unfathomable', 'success', 'with', 'the', 'opposite', 'gender', 'is', 'presumed', 'lost', 'at', 'sea', 'sandler', 's', 'character', 'shecker', 'gets', 'his', 'big', 'break', 'dickie', 'is', 'not', 'dead', 'he', 's', 'rather', 'locked', 'in', 'the', 'bathroom', 'presumably', 'sea', 'sick', 'perhaps', 'from', 'his', 'mouth', 'he', 'just', 'vomited', 'the', 'worst', 'film', 'of', 'all', 'time']\n"
     ]
    }
   ],
   "source": [
    "words_list = text.lower().split()\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 停用词的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>利用nltk库和nltk.corpus语料库导入英语的停用词列表</strong><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "{'herself', 'are', 'd', 'how', 'from', 'they', 'by', 'both', 'who', 'before', 'she', 'those', 'or', 'ain', 'haven', 'will', 'a', 'against', 'why', 'won', 'where', 'this', 'our', 'doing', 'that', 'too', 'very', 'at', 'while', 'doesn', 'these', 'me', 'been', 'until', 'about', 'shouldn', 'for', 'itself', 'hadn', 'same', 'yourself', 'ourselves', 'above', 'few', 'an', 'their', 'her', 'if', 'mustn', 'had', 'on', 'be', 'being', 'down', 'wasn', 'hers', 'myself', 'were', 'nor', 'you', 'here', 'now', 've', 't', 'when', 'having', 'then', 'did', 'own', 'weren', 'can', 'ours', 'him', 'is', 'don', 'further', 'each', 'because', 'shan', 'so', 'needn', 'his', 'have', 'i', 'we', 'and', 'my', 'hasn', 'wouldn', 'more', 'am', 'such', 'o', 'of', 'out', 'not', 'into', 'some', 'he', 'the', 'up', 'there', 'any', 'just', 'them', 'has', 'what', 'should', 'was', 'themselves', 'most', 'only', 'whom', 'which', 'mightn', 'all', 'through', 'it', 'ma', 'm', 'over', 'than', 'between', 'as', 'after', 'its', 'theirs', 'y', 'with', 'does', 're', 'isn', 'yourselves', 'didn', 'do', 'but', 'to', 'yours', 'aren', 'your', 'once', 'himself', 'under', 'during', 'again', 'below', 'off', 'couldn', 'll', 'no', 'other', 'in', 's'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download()\n",
    "stopwords_list = set(stopwords.words(\"english\"))           # 英文的停用词集合\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>5,&emsp;去掉将这条影评的文本内容中的停用词</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['friend', 'mine', 'bought', 'film', 'even', 'grossly', 'overpriced', 'despite', 'featuring', 'big', 'names', 'adam', 'sandler', 'billy', 'bob', 'thornton', 'incredibly', 'talented', 'burt', 'young', 'film', 'funny', 'taking', 'chisel', 'hammering', 'straight', 'earhole', 'uses', 'tired', 'bottom', 'barrel', 'comedic', 'techniques', 'consistently', 'breaking', 'fourth', 'wall', 'sandler', 'talks', 'audience', 'seemingly', 'pointless', 'montages', 'hot', 'girls', 'adam', 'sandler', 'plays', 'waiter', 'cruise', 'ship', 'wants', 'make', 'successful', 'comedian', 'order', 'become', 'successful', 'women', 'ship', 'resident', 'comedian', 'shamelessly', 'named', 'dickie', 'due', 'unfathomable', 'success', 'opposite', 'gender', 'presumed', 'lost', 'sea', 'sandler', 'character', 'shecker', 'gets', 'big', 'break', 'dickie', 'dead', 'rather', 'locked', 'bathroom', 'presumably', 'sea', 'sick', 'perhaps', 'mouth', 'vomited', 'worst', 'film', 'time']\n"
     ]
    }
   ],
   "source": [
    "words_list_rm_stopwords = [w for w in words_list if not w in stopwords_list]\n",
    "print(words_list_rm_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>6,&emsp;最后将清洗后的单词列表用空格分隔成一条字符串</storng>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friend mine bought film even grossly overpriced despite featuring big names adam sandler billy bob thornton incredibly talented burt young film funny taking chisel hammering straight earhole uses tired bottom barrel comedic techniques consistently breaking fourth wall sandler talks audience seemingly pointless montages hot girls adam sandler plays waiter cruise ship wants make successful comedian order become successful women ship resident comedian shamelessly named dickie due unfathomable success opposite gender presumed lost sea sandler character shecker gets big break dickie dead rather locked bathroom presumably sea sick perhaps mouth vomited worst film time'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = \" \".join(words_list_rm_stopwords)\n",
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个文本处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_review(raw_review, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    输入: 一条原始影评,\n",
    "    输出: 一条经过清洗后的影评。\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(raw_review, \"lxml\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    words_list = text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        words_list_rm_stopwords = [w for w in words_list if not w in stopwords_list]\n",
    "        document = \" \".join(words_list_rm_stopwords)\n",
    "    else:\n",
    "        document = \" \".join(words_list)\n",
    "    return document\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将每条影评清洗后保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 影评数量\n",
    "num_train_reviews = data_train[\"review\"].size\n",
    "\n",
    "# 初始化一个空列表保存每条影评清洗后的内容\n",
    "clean_train_reviews = []\n",
    "\n",
    "for i in range(0, num_train_reviews):\n",
    "    review = data_train[\"review\"][i]\n",
    "    clean_train_reviews.append(clean_review(review, remove_stopwords=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从词袋模型中创建特征(使用scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 <strong>计算词频</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化CountVectorizer对象,它是scikit-learn的词袋模型工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             ngram_range = (1, 3),\n",
    "                             max_features = 5000,\n",
    "                             tokenizer = None,  \n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>CountVectorizer对象vectorizer的fit_transform()方法起到了两个函数的作用：</strong><br>\n",
    "&emsp;第一: &emsp;<strong>拟合模型并且学到词汇</strong><br>\n",
    "&emsp;第二: &emsp;<strong>将训练数据转化为特征向量</strong><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_X = vectorizer.fit_transform(clean_train_reviews)\n",
    "data_train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 <strong>使用TF-IDF进行特征提取</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(sublinear_tf=True)\n",
    "data_train_X_tfidf = tfidf_transformer.fit_transform(data_train_X)\n",
    "data_train_X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_reviews = data_test[\"review\"].size\n",
    "clean_test_reviews = []\n",
    "\n",
    "for i in range(0, num_test_reviews):\n",
    "    review = data_test[\"review\"][i]\n",
    "    clean_test_reviews.append(clean_review(review, remove_stopwords=True))\n",
    "    \n",
    "data_test_X = vectorizer.transform(clean_test_reviews)\n",
    "data_test_X_tfidf = tfidf_transformer.transform(data_test_X)\n",
    "data_test_X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93587929600000008"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model_auc = cross_val_score(nb_model, data_train_X_tfidf, data_train[\"sentiment\"], cv=10, scoring=\"roc_auc\").mean()\n",
    "nb_model_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性支持向量机分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94756691199999987"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC(C=1)\n",
    "svc_model_auc = cross_val_score(svc_model, data_train_X_tfidf, data_train[\"sentiment\"], cv=10, scoring=\"roc_auc\").mean()\n",
    "svc_model_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic回归分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95550905600000002"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(C=1.0)\n",
    "logistic_model_auc = cross_val_score(logistic_model, data_train_X_tfidf, data_train[\"sentiment\"], cv=10, scoring=\"roc_auc\").mean()\n",
    "logistic_model_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降(SGD)分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95466809600000013"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model_auc = cross_val_score(sgd_model, data_train_X_tfidf, data_train[\"sentiment\"], cv=10, scoring=\"roc_auc\").mean()\n",
    "sgd_model_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86589513600000001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model_auc = cross_val_score(rf_model, data_train_X_tfidf, data_train[\"sentiment\"], cv=10, scoring=\"roc_auc\").mean()\n",
    "rf_model_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 提交预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>不调参了, 也不模型融合了</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic回归</td>\n",
       "      <td>0.955509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>随机梯度下降</td>\n",
       "      <td>0.954668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>支持向量机</td>\n",
       "      <td>0.947567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>朴素贝叶斯</td>\n",
       "      <td>0.935879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>随机森林</td>\n",
       "      <td>0.865895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model     score\n",
       "2  Logistic回归  0.955509\n",
       "3      随机梯度下降  0.954668\n",
       "1       支持向量机  0.947567\n",
       "0       朴素贝叶斯  0.935879\n",
       "4        随机森林  0.865895"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        \"model\": [\"朴素贝叶斯\", \"支持向量机\", \"Logistic回归\", \"随机梯度下降\", \"随机森林\"],\n",
    "        \"score\": [nb_model_auc, svc_model_auc, logistic_model_auc, sgd_model_auc, rf_model_auc]\n",
    "    })\n",
    "\n",
    "df.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_model = nb_model.fit(data_train_X_tfidf, data_train[\"sentiment\"])\n",
    "nb_result = nb_model.predict(data_test_X_tfidf)\n",
    "\n",
    "svc_model = svc_model.fit(data_train_X_tfidf, data_train[\"sentiment\"])\n",
    "svc_result = svc_model.predict(data_test_X_tfidf)\n",
    "\n",
    "logistic_model = logistic_model.fit(data_train_X_tfidf, data_train[\"sentiment\"])\n",
    "logistic_result = logistic_model.predict(data_test_X_tfidf)\n",
    "\n",
    "sgd_model = sgd_model.fit(data_train_X_tfidf, data_train[\"sentiment\"])\n",
    "sgd_result = sgd_model.predict(data_test_X_tfidf)\n",
    "\n",
    "rf_model = rf_model.fit(data_train_X_tfidf, data_train[\"sentiment\"])\n",
    "rf_result = rf_model.predict(data_test_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = 0.2 * nb_result + 0.2 * svc_result + 0.2 * logistic_result + 0.2 * sgd_result + 0.2 * rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.489248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.447065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment\n",
       "count  25000.000000\n",
       "mean       0.489248\n",
       "std        0.447065\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.600000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        \"id\": data_test[\"id\"],\n",
    "        \"sentiment\": result,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"sentiment\"] <= 0.4, \"sentiment\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"sentiment\"] >= 0.6, \"sentiment\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"output.csv\", header=True, index=False, quoting=3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "532px",
    "left": "0px",
    "right": "1154px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
